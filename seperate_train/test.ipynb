{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import schnetpack as spk\n",
    "from schnetpack.datasets import QM9\n",
    "import schnetpack.transform as trn\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "qm9tut = './qm9tut'\n",
    "if not os.path.exists('qm9tut'):\n",
    "    os.makedirs(qm9tut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "qm9data = QM9(\n",
    "    './qm9.db',\n",
    "    batch_size=100,\n",
    "    num_train=1000,\n",
    "    num_val=1000,\n",
    "    transforms=[\n",
    "        trn.ASENeighborList(cutoff=5.),\n",
    "        trn.RemoveOffsets(QM9.U0, remove_mean=True, remove_atomrefs=True),\n",
    "        trn.CastTo32()\n",
    "    ],\n",
    "    property_units={QM9.U0: 'eV'},\n",
    "    num_workers=1,\n",
    "    split_file=os.path.join(qm9tut, \"split.npz\"),\n",
    "    pin_memory=True, # set to false, when not using a GPU\n",
    "    load_properties=[QM9.U0], #only load U0 property\n",
    ")\n",
    "qm9data.prepare_data()\n",
    "qm9data.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U0 of hyrogen: -13.613121032714844 eV\n",
      "U0 of carbon: -1029.863037109375 eV\n",
      "U0 of oxygen: -2042.611083984375 eV\n"
     ]
    }
   ],
   "source": [
    "atomrefs = qm9data.train_dataset.atomrefs\n",
    "print('U0 of hyrogen:', atomrefs[QM9.U0][1].item(), 'eV')\n",
    "print('U0 of carbon:', atomrefs[QM9.U0][6].item(), 'eV')\n",
    "print('U0 of oxygen:', atomrefs[QM9.U0][8].item(), 'eV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean atomization energy / atom: -4.245704495720481\n",
      "Std. dev. atomization energy / atom: 0.19056816253783845\n"
     ]
    }
   ],
   "source": [
    "means, stddevs = qm9data.get_stats(\n",
    "    QM9.U0, divide_by_atoms=True, remove_atomref=True\n",
    ")\n",
    "print('Mean atomization energy / atom:', means.item())\n",
    "print('Std. dev. atomization energy / atom:', stddevs.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 5.\n",
    "n_atom_basis = 30\n",
    "\n",
    "pairwise_distance = spk.atomistic.PairwiseDistances() # calculates pairwise distances between atoms\n",
    "radial_basis = spk.nn.GaussianRBF(n_rbf=20, cutoff=cutoff)\n",
    "schnet = spk.representation.SchNet(\n",
    "    n_atom_basis=n_atom_basis, n_interactions=3,\n",
    "    radial_basis=radial_basis,\n",
    "    cutoff_fn=spk.nn.CosineCutoff(cutoff)\n",
    ")\n",
    "pred_U0 = spk.atomistic.Atomwise(n_in=n_atom_basis, output_key=QM9.U0)\n",
    "\n",
    "nnpot = spk.model.NeuralNetworkPotential(\n",
    "    representation=schnet,\n",
    "    input_modules=[pairwise_distance],\n",
    "    output_modules=[pred_U0],\n",
    "    postprocessors=[trn.CastTo64(), trn.AddOffsets(QM9.U0, add_mean=True, add_atomrefs=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nnpot.representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_U0 = spk.task.ModelOutput(\n",
    "    name=QM9.U0,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    loss_weight=1.,\n",
    "    metrics={\n",
    "        \"MAE\": torchmetrics.MeanAbsoluteError()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmahovmand/Documents/DTU/kandidat/2_semester_fall_2023/02456_Deep_learning/final_project/DeepLearningProject/.venv/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    }
   ],
   "source": [
    "task = spk.task.AtomisticTask(\n",
    "    model=nnpot,\n",
    "    outputs=[output_U0],\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    optimizer_args={\"lr\": 1e-4}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type                   | Params\n",
      "---------------------------------------------------\n",
      "0 | model   | NeuralNetworkPotential | 16.4 K\n",
      "1 | outputs | ModuleList             | 0     \n",
      "---------------------------------------------------\n",
      "16.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.4 K    Total params\n",
      "0.066     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmahovmand/Documents/DTU/kandidat/2_semester_fall_2023/02456_Deep_learning/final_project/DeepLearningProject/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  8.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmahovmand/Documents/DTU/kandidat/2_semester_fall_2023/02456_Deep_learning/final_project/DeepLearningProject/.venv/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 100. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmahovmand/Documents/DTU/kandidat/2_semester_fall_2023/02456_Deep_learning/final_project/DeepLearningProject/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/emmahovmand/Documents/DTU/kandidat/2_semester_fall_2023/02456_Deep_learning/final_project/DeepLearningProject/.venv/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 10/10 [00:07<00:00,  1.26it/s, v_num=1, val_loss=6.700]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 10/10 [00:07<00:00,  1.26it/s, v_num=1, val_loss=6.700]\n"
     ]
    }
   ],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(save_dir=qm9tut)\n",
    "callbacks = [\n",
    "    spk.train.ModelCheckpoint(\n",
    "        model_path=os.path.join(qm9tut, \"best_inference_model\"),\n",
    "        save_top_k=1,\n",
    "        monitor=\"val_loss\"\n",
    "    )\n",
    "]\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    default_root_dir=qm9tut,\n",
    "    max_epochs=3, # for testing, we restrict the number of epochs\n",
    ")\n",
    "trainer.fit(task, datamodule=qm9data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SchNet(\n",
       "  (radial_basis): GaussianRBF()\n",
       "  (cutoff_fn): CosineCutoff()\n",
       "  (embedding): Embedding(100, 30, padding_idx=0)\n",
       "  (interactions): ModuleList(\n",
       "    (0-2): 3 x SchNetInteraction(\n",
       "      (in2f): Dense(\n",
       "        in_features=30, out_features=30, bias=False\n",
       "        (activation): Identity()\n",
       "      )\n",
       "      (f2out): Sequential(\n",
       "        (0): Dense(in_features=30, out_features=30, bias=True)\n",
       "        (1): Dense(\n",
       "          in_features=30, out_features=30, bias=True\n",
       "          (activation): Identity()\n",
       "        )\n",
       "      )\n",
       "      (filter_network): Sequential(\n",
       "        (0): Dense(in_features=20, out_features=30, bias=True)\n",
       "        (1): Dense(\n",
       "          in_features=30, out_features=30, bias=True\n",
       "          (activation): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnpot.representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(\n",
       "  in_features=30, out_features=30, bias=True\n",
       "  (activation): Identity()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input\n",
    "nnpot.representation.interactions[2].in2f\n",
    "\n",
    "# output\n",
    "nnpot.representation.interactions[2].f2out[1]\n",
    "nnpot.representation.interactions[2].f2out[1] #.out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to operator (1024431672.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    tensorboard --logdir=qm9tut/default\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to operator\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir=qm9tut/default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from ase import Atoms\n",
    "\n",
    "best_model = torch.load(os.path.join(qm9tut, 'best_inference_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1957, -0.0522,  0.1432, -0.1578, -0.0266,  0.1675, -0.1530,  0.1505,\n",
       "          0.0091, -0.2785, -0.1529, -0.1676,  0.3112, -0.0173, -0.0844, -0.0365,\n",
       "         -0.0081,  0.0414, -0.2603, -0.0626, -0.2589, -0.3102, -0.0970,  0.2427,\n",
       "          0.2405,  0.0425,  0.2449, -0.2071, -0.1293,  0.0557],\n",
       "        [-0.0068, -0.3051, -0.1168,  0.1682, -0.0147,  0.1787, -0.3157, -0.1569,\n",
       "          0.1138,  0.0716, -0.0161,  0.2184,  0.2255, -0.0469,  0.0354, -0.0888,\n",
       "          0.2544,  0.1859,  0.2389,  0.0581,  0.0895,  0.1545, -0.2874, -0.1504,\n",
       "         -0.2749, -0.1167,  0.1257, -0.0366, -0.2447, -0.1511],\n",
       "        [ 0.1583,  0.0902,  0.2954, -0.2632,  0.2900, -0.0366, -0.2473, -0.2278,\n",
       "          0.0306,  0.0462, -0.1680, -0.2163,  0.2333, -0.1983,  0.0510, -0.1190,\n",
       "          0.0661, -0.2612,  0.1069, -0.1161,  0.0457, -0.1743, -0.1387, -0.3095,\n",
       "          0.2604,  0.1649,  0.0495, -0.1016,  0.2793, -0.2042],\n",
       "        [-0.2777, -0.2464,  0.0634,  0.1861,  0.2995,  0.2399,  0.1869, -0.0208,\n",
       "          0.0467,  0.1981,  0.1081, -0.0063,  0.1264, -0.2459, -0.2834, -0.2578,\n",
       "         -0.3136,  0.2736, -0.0510, -0.2236,  0.2215,  0.0151,  0.1587, -0.1917,\n",
       "         -0.2219,  0.0798,  0.0602, -0.1768,  0.1436,  0.0534],\n",
       "        [ 0.2749,  0.1215, -0.1259,  0.1634, -0.2245, -0.1157,  0.1485, -0.0135,\n",
       "          0.2504,  0.2348, -0.2207,  0.1685, -0.1785, -0.1323, -0.2699, -0.2969,\n",
       "         -0.2208, -0.3035,  0.1452,  0.1239,  0.3063,  0.2033, -0.2033, -0.2086,\n",
       "          0.0380,  0.2531,  0.1855, -0.1037, -0.1319,  0.2754],\n",
       "        [-0.2160,  0.2806,  0.2490, -0.2091,  0.1872,  0.2598,  0.0130,  0.2221,\n",
       "         -0.2769, -0.0186, -0.0561,  0.0146, -0.0603, -0.1740, -0.1291, -0.2734,\n",
       "         -0.2506,  0.1020, -0.2624,  0.3148, -0.2339, -0.2468,  0.3160,  0.1174,\n",
       "          0.1767, -0.1680,  0.0020,  0.1079, -0.1791, -0.3117],\n",
       "        [-0.2503,  0.0581,  0.1457,  0.0199, -0.0494, -0.0835,  0.2243,  0.1828,\n",
       "          0.2308,  0.1874, -0.0634,  0.2809,  0.0668,  0.1922,  0.3137, -0.2957,\n",
       "         -0.0647,  0.1763,  0.2829, -0.0006,  0.0515,  0.0364,  0.2928,  0.1214,\n",
       "          0.0487, -0.0811,  0.0886,  0.2312,  0.1833,  0.0969],\n",
       "        [ 0.2032,  0.0599,  0.0793, -0.1161, -0.2880, -0.1652, -0.0069, -0.1002,\n",
       "          0.0387,  0.1177, -0.0135,  0.0021, -0.1993, -0.2597,  0.1104,  0.2286,\n",
       "         -0.1037,  0.1159, -0.2285,  0.2812,  0.1535,  0.1293,  0.1455, -0.1063,\n",
       "         -0.1311, -0.1974, -0.2380,  0.2349, -0.2070,  0.0447],\n",
       "        [ 0.1354,  0.1564,  0.2854, -0.2010, -0.0164, -0.1860, -0.0088,  0.2540,\n",
       "          0.1527,  0.0449,  0.1538,  0.1225, -0.2468, -0.2753, -0.1918,  0.0281,\n",
       "         -0.1024,  0.0792,  0.0198,  0.2820, -0.0669,  0.0851, -0.3007,  0.1954,\n",
       "          0.1157,  0.2966,  0.1415,  0.2901,  0.1112,  0.3120],\n",
       "        [-0.0581,  0.1639, -0.0424,  0.1079,  0.1446,  0.0329, -0.0777,  0.0011,\n",
       "          0.1267, -0.0643,  0.0744,  0.1588,  0.0343, -0.1945,  0.1786, -0.2032,\n",
       "         -0.2798, -0.2139, -0.0137,  0.0707,  0.2787, -0.1531, -0.0118, -0.2250,\n",
       "          0.0528,  0.0447,  0.2353,  0.2829,  0.0258,  0.2733],\n",
       "        [ 0.0357, -0.3175,  0.0263,  0.0407,  0.1781, -0.2205, -0.1548,  0.1358,\n",
       "          0.2789, -0.1643, -0.2843, -0.2631, -0.1874, -0.2515,  0.1155, -0.1419,\n",
       "          0.2714, -0.1947,  0.0674, -0.0169, -0.0047,  0.0930, -0.1649, -0.2407,\n",
       "          0.2574,  0.1898, -0.2072,  0.0633,  0.0937,  0.1568],\n",
       "        [ 0.2910,  0.1385, -0.1367, -0.0515,  0.0286, -0.2238,  0.0989,  0.0333,\n",
       "         -0.1347, -0.1736,  0.0980, -0.3040, -0.0569, -0.2611, -0.2229,  0.1978,\n",
       "         -0.2254, -0.1310, -0.2750,  0.2897,  0.0700,  0.1824, -0.3047,  0.1181,\n",
       "         -0.0327, -0.2514, -0.0761, -0.1717, -0.1829, -0.0350],\n",
       "        [ 0.0316,  0.0922, -0.2904,  0.1766, -0.1720, -0.3139, -0.0415, -0.1671,\n",
       "         -0.1302, -0.0998,  0.0908, -0.2157, -0.1943,  0.2064,  0.0141,  0.1083,\n",
       "          0.0678,  0.1479,  0.1508, -0.1741, -0.2265, -0.2848, -0.3132,  0.2342,\n",
       "          0.0366,  0.1369, -0.0655,  0.2002, -0.3036,  0.0930],\n",
       "        [-0.0677, -0.0251, -0.0737, -0.2952,  0.2002,  0.0652, -0.2588,  0.2703,\n",
       "          0.1177,  0.2313,  0.3138, -0.1715, -0.1332,  0.3079,  0.0545, -0.0649,\n",
       "          0.2500, -0.2588,  0.2584, -0.2564,  0.2882,  0.2674, -0.1999, -0.0181,\n",
       "          0.0090,  0.1800, -0.1770, -0.2587,  0.2733,  0.2318],\n",
       "        [-0.0277,  0.0196, -0.0615, -0.0401, -0.2822,  0.2493,  0.0871, -0.1658,\n",
       "          0.2709, -0.3020, -0.0647,  0.0126,  0.0078,  0.1472,  0.0076, -0.0910,\n",
       "          0.1841,  0.0950, -0.1229,  0.1292, -0.1386, -0.1743, -0.0487,  0.2971,\n",
       "          0.2825,  0.0774,  0.1644,  0.0102, -0.0691, -0.1370],\n",
       "        [-0.2688,  0.0112, -0.0102,  0.0128,  0.2448,  0.1758,  0.0882, -0.1889,\n",
       "          0.1831,  0.0746,  0.1299, -0.0289, -0.0984, -0.1875, -0.0289,  0.2071,\n",
       "         -0.2839,  0.2953,  0.2031,  0.1227,  0.2678,  0.1859, -0.2610, -0.1343,\n",
       "          0.1666,  0.0761, -0.0105, -0.1351,  0.1346,  0.0395],\n",
       "        [ 0.1160,  0.0409, -0.1730,  0.1754,  0.0085, -0.1928, -0.1596,  0.1750,\n",
       "          0.1842, -0.1159,  0.0613,  0.1199,  0.3068,  0.0255, -0.1712,  0.0186,\n",
       "          0.0953, -0.1454, -0.1568,  0.0984,  0.2624,  0.0724,  0.0698,  0.1448,\n",
       "         -0.1625,  0.2422,  0.0922, -0.1204,  0.0806,  0.1522],\n",
       "        [ 0.1601,  0.3080, -0.0359, -0.1234, -0.0475,  0.2173,  0.1752, -0.1711,\n",
       "         -0.0375,  0.0452, -0.0865,  0.1304,  0.1524,  0.2181, -0.2734,  0.2034,\n",
       "          0.2187, -0.0204,  0.2453,  0.0822,  0.1187,  0.1916, -0.0013, -0.2001,\n",
       "         -0.1966, -0.2639, -0.2737, -0.1414, -0.0437,  0.1298],\n",
       "        [-0.2362, -0.1909, -0.1317, -0.1335, -0.1587,  0.1354,  0.2881, -0.0599,\n",
       "          0.0091, -0.0276, -0.3174,  0.0379,  0.2789,  0.1720,  0.1202,  0.1695,\n",
       "         -0.2966,  0.0743, -0.0605, -0.1502,  0.3003,  0.3069,  0.1541,  0.2326,\n",
       "          0.2682, -0.1031,  0.1038, -0.2862,  0.1398,  0.0737],\n",
       "        [ 0.1463, -0.2535,  0.2875,  0.2034,  0.2927,  0.2158, -0.2137,  0.1415,\n",
       "          0.1016,  0.0768,  0.1298, -0.1582,  0.2759, -0.1241, -0.2409,  0.1735,\n",
       "          0.0839, -0.2628, -0.0119,  0.0892,  0.2768, -0.3058, -0.1600, -0.2447,\n",
       "          0.2597,  0.0415,  0.3108, -0.2324, -0.2743,  0.2927],\n",
       "        [ 0.2340, -0.0753,  0.1713, -0.1858,  0.2602,  0.2242, -0.0924,  0.1667,\n",
       "         -0.2074,  0.0674,  0.2345,  0.1418,  0.0243,  0.1121, -0.1362, -0.2085,\n",
       "         -0.1579, -0.2949,  0.1159, -0.0184,  0.3095, -0.1867, -0.2237, -0.0053,\n",
       "         -0.2094,  0.2102,  0.2252, -0.2673, -0.2017, -0.0967],\n",
       "        [-0.1445,  0.0563,  0.2457, -0.1594, -0.2916, -0.2332, -0.0811, -0.0444,\n",
       "          0.0707, -0.2169, -0.2300, -0.0311,  0.0732, -0.2440, -0.0137,  0.2677,\n",
       "         -0.2673,  0.0031, -0.0666,  0.2694, -0.1816,  0.1541,  0.0929, -0.1059,\n",
       "         -0.1616,  0.1663, -0.1544, -0.1327,  0.2223,  0.2073],\n",
       "        [ 0.1812, -0.0679,  0.1289, -0.0941,  0.1942, -0.0453, -0.2358,  0.0134,\n",
       "         -0.2393, -0.0149, -0.0030, -0.1017, -0.1536,  0.1452, -0.2595, -0.0778,\n",
       "         -0.1218,  0.2899,  0.0444, -0.1717, -0.3159,  0.1180, -0.0282,  0.0488,\n",
       "          0.2206,  0.0248, -0.0992,  0.0319, -0.1719, -0.3015],\n",
       "        [-0.1873, -0.0856,  0.2522, -0.0948,  0.1747, -0.2428,  0.0733, -0.3071,\n",
       "         -0.0844, -0.2728, -0.0111,  0.2754,  0.1502,  0.1769, -0.1297,  0.3169,\n",
       "         -0.0110, -0.1916,  0.2749, -0.2029, -0.2559,  0.2783,  0.2210, -0.1430,\n",
       "         -0.0056,  0.2030,  0.2277,  0.1472,  0.2556, -0.3045],\n",
       "        [-0.1330,  0.0354, -0.1845, -0.2533,  0.0408, -0.1202,  0.1694,  0.2107,\n",
       "          0.1945, -0.1443, -0.1833,  0.1534,  0.0063, -0.2893, -0.1731,  0.0957,\n",
       "         -0.1007, -0.0058,  0.2142, -0.1328, -0.0805,  0.2635,  0.3141, -0.1920,\n",
       "          0.1053,  0.0533, -0.0770, -0.1275,  0.0454, -0.1736],\n",
       "        [ 0.1887,  0.2246,  0.0136, -0.2583,  0.3063, -0.0324, -0.2080,  0.0554,\n",
       "         -0.1135, -0.2900,  0.1305,  0.0851,  0.0795,  0.3102, -0.1570, -0.1195,\n",
       "          0.3114,  0.1550,  0.2302, -0.1983,  0.1528, -0.2707, -0.1502,  0.2488,\n",
       "         -0.1618, -0.0433,  0.1141,  0.2370, -0.1711,  0.0115],\n",
       "        [ 0.0980, -0.0262,  0.1904,  0.2460, -0.0426, -0.1088, -0.1810, -0.2284,\n",
       "         -0.0681,  0.1662,  0.1195, -0.0664,  0.0993,  0.1820, -0.2967,  0.2100,\n",
       "          0.1855,  0.1057, -0.2569,  0.0565, -0.2844,  0.1508, -0.1670, -0.1714,\n",
       "         -0.1809, -0.0628, -0.2928,  0.2855, -0.2425, -0.0266],\n",
       "        [ 0.1051,  0.2773,  0.1107, -0.1820, -0.0545,  0.0568, -0.1574, -0.2151,\n",
       "          0.2709,  0.0009,  0.1794, -0.1549, -0.3120, -0.2880,  0.0891, -0.0984,\n",
       "          0.2483, -0.0628,  0.0931,  0.2940,  0.0549, -0.3061,  0.0216,  0.1134,\n",
       "         -0.0272, -0.0876, -0.3125,  0.0535, -0.0517,  0.2880],\n",
       "        [-0.0518,  0.0705, -0.2309,  0.2564, -0.2394, -0.1686,  0.0625,  0.1277,\n",
       "          0.1082, -0.2879, -0.0174, -0.1696,  0.2866,  0.0842, -0.2355,  0.3066,\n",
       "          0.2264,  0.2445,  0.2071, -0.2416,  0.2807,  0.2017, -0.0221, -0.0485,\n",
       "         -0.1528,  0.2151,  0.2534, -0.2343, -0.0109, -0.1676],\n",
       "        [-0.2581, -0.0683,  0.0175, -0.1624, -0.3104,  0.0236, -0.1986, -0.2408,\n",
       "         -0.1568,  0.2443,  0.1973, -0.1425,  0.0325, -0.1904, -0.1208,  0.2025,\n",
       "          0.2831,  0.2498, -0.2766,  0.3042,  0.2935, -0.2468, -0.2046, -0.0854,\n",
       "         -0.1575, -0.2889,  0.2015,  0.0359, -0.0278, -0.2255]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.representation.interactions[2].f2out[1].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result dictionary: {'energy_U0': tensor([-11943.9487, -11506.3155, -13326.7959, -10527.4633, -12887.8292,\n",
      "        -11332.6160, -12418.2834, -14844.9734, -11492.3204,  -9916.1579,\n",
      "        -11819.2054, -10527.1741, -11542.2847, -12485.4260, -11944.4545,\n",
      "        -12520.6219, -11368.2903, -11807.3646, -12244.1830, -12555.8003,\n",
      "         -8918.0763,  -8479.8919, -11806.3710,  -9458.3451, -12556.1027,\n",
      "        -10875.3029, -10390.0844, -10930.6195, -11439.7683, -10965.6649,\n",
      "        -11806.4312, -10299.4354, -11438.8387,  -8917.9874, -10456.5376,\n",
      "        -10563.2562, -11541.6571,  -8827.5483,  -9841.8112,  -9932.3456,\n",
      "        -10930.2407, -10528.0026, -11333.0546, -11506.1835, -11404.3444,\n",
      "        -12382.2623, -11470.5162, -12020.2315,  -9987.0961, -15610.5895,\n",
      "        -10563.2871, -11470.8388,  -9513.3478, -11332.7022, -11979.3622,\n",
      "        -11332.8466, -11380.7998,  -9931.7666, -10299.3313, -12016.0503,\n",
      "        -10491.8307, -10966.1857, -11506.4515, -11368.6428, -12785.3460,\n",
      "         -9915.8773, -11577.9113, -10840.1487,  -8480.0946, -12520.7585,\n",
      "        -10875.3789, -11909.1269, -10299.3772, -10527.5272, -11403.7924,\n",
      "        -11541.9082, -10318.9249, -11506.0642, -10634.4164, -11312.8620,\n",
      "        -10634.5048, -11578.0597, -11506.5369, -10491.7116, -11841.3808,\n",
      "        -11506.0014,  -9442.1530,  -9987.4192, -10894.6999, -10965.9650,\n",
      "        -11000.7935, -11542.6660, -11487.9080, -11506.7397, -10930.4121,\n",
      "        -11506.0916,  -9932.6251,  -9422.9205, -12556.1574, -10965.3234],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "for batch in qm9data.test_dataloader():\n",
    "    result = best_model(batch)\n",
    "    print(\"Result dictionary:\", result)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = spk.interfaces.AtomsConverter(neighbor_list=trn.ASENeighborList(cutoff=5.), dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = np.array([6, 1, 1, 1, 1])\n",
    "positions = np.array([[-0.0126981359, 1.0858041578, 0.0080009958],\n",
    "                      [0.002150416, -0.0060313176, 0.0019761204],\n",
    "                      [1.0117308433, 1.4637511618, 0.0002765748],\n",
    "                      [-0.540815069, 1.4475266138, -0.8766437152],\n",
    "                      [-0.5238136345, 1.4379326443, 0.9063972942]])\n",
    "atoms = Atoms(numbers=numbers, positions=positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: ['_n_atoms', '_atomic_numbers', '_positions', '_cell', '_pbc', '_idx', '_idx_i_local', '_idx_j_local', '_offsets', '_idx_m', '_idx_j', '_idx_i']\n",
      "Prediction: tensor([-1103.8020], dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputs = converter(atoms)\n",
    "\n",
    "print('Keys:', list(inputs.keys()))\n",
    "\n",
    "pred = best_model(inputs)\n",
    "\n",
    "print('Prediction:', pred[QM9.U0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['energy_U0'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:schnetpack.interfaces.ase_interface:Loading model from ./qm9tut/best_inference_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: -1103.8019646406174\n"
     ]
    }
   ],
   "source": [
    "calculator = spk.interfaces.SpkCalculator(\n",
    "    model_file=os.path.join(qm9tut, \"best_inference_model\"), # path to model\n",
    "    neighbor_list=trn.ASENeighborList(cutoff=5.), # neighbor list\n",
    "    energy_key=QM9.U0, # name of energy property in model\n",
    "    energy_unit=\"eV\", # units of energy property\n",
    "    device=\"cpu\", # device for computation\n",
    ")\n",
    "atoms.set_calculator(calculator)\n",
    "print('Prediction:', atoms.get_total_energy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
